{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GROUP 7 (CNN).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPL5mAgmYS9gZIzwSFK5rHP"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPT_x8bPM16U"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Direktori"
      ],
      "metadata": {
        "id": "kZrzPSihP19O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/drive/My Drive/AI/'\n",
        "!ls \"/content/drive/My Drive/AI/\""
      ],
      "metadata": {
        "id": "_a1e8xMAP4rE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dir All\n",
        "bahan_dir = os.path.join(base_dir, 'bahan')\n",
        "train_dir = os.path.join(base_dir, 'latih')\n",
        "validation_dir = os.path.join(base_dir, 'validasi')"
      ],
      "metadata": {
        "id": "sYIOYq8LRZhF"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dir Bahan\n",
        "rodadua_dir = os.path.join(bahan_dir, 'rodadua/')\n",
        "rodaempat_dir = os.path.join(bahan_dir, 'rodaempat/')\n",
        "\n",
        "print(\"Jumlah Data Train Tiap Kelas\")\n",
        "print('Jumlah gambar Kendaraan Roda Dua :', len(os.listdir(rodadua_dir)))\n",
        "print('Jumlah gambar Kendaraan Roda Empat :', len(os.listdir(rodaempat_dir)))"
      ],
      "metadata": {
        "id": "YD7Nt8QtR-Bc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dir latih/train\n",
        "train_rodadua = os.path.join(train_dir, 'rodadua/')\n",
        "train_rodaempat = os.path.join(train_dir, 'rodaempat/')\n",
        "\n",
        "#dir validasi\n",
        "validation_rodadua = os.path.join(validation_dir, 'rodadua/')\n",
        "validation_rodaempat = os.path.join(validation_dir, 'rodaempat/')"
      ],
      "metadata": {
        "id": "IcI5I5GxU6iF"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare Data Set"
      ],
      "metadata": {
        "id": "x7JsAiCPVjj8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from shutil import copyfile\n",
        "\n",
        "def train_val_split(source, train, val, train_ratio):\n",
        "  total_size = len(os.listdir(source))\n",
        "  train_size = int(train_ratio * total_size)\n",
        "  val_size = total_size - train_size\n",
        "\n",
        "  randomized = random.sample(os.listdir(source), total_size)\n",
        "  train_files = randomized[0:train_size]\n",
        "  val_files = randomized[train_size:total_size]\n",
        "\n",
        "  for i in train_files:\n",
        "    i_file = source + i\n",
        "    destination = train + i\n",
        "    copyfile(i_file, destination)\n",
        "\n",
        "  for i in val_files:\n",
        "    i_file = source + i\n",
        "    destination = val + i\n",
        "    copyfile(i_file, destination)\n",
        "\n",
        "#ratio Train dan validasi\n",
        "train_ratio = 0.9  \n",
        "\n",
        "\n",
        "#training\n",
        "source_00 = rodadua_dir\n",
        "train_00 = train_rodadua\n",
        "val_00 = validation_rodadua\n",
        "train_val_split(source_00, train_00, val_00, train_ratio)\n",
        "\n",
        "#validasi\n",
        "source_01 = rodaempat_dir\n",
        "train_01 = train_rodaempat\n",
        "val_01 = validation_rodaempat\n",
        "train_val_split(source_01, train_01, val_01, train_ratio)"
      ],
      "metadata": {
        "id": "SKs008U3Vl1s"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Jumlah All rodadua    :', len(os.listdir(rodadua_dir)))\n",
        "print('Jumlah Train rodadua  :', len(os.listdir(train_rodadua)))\n",
        "print('Jumlah Val rodadua    :', len(os.listdir(validation_rodadua)))"
      ],
      "metadata": {
        "id": "tXPMUmsDZC-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "PJ56wJIlpE9h"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "                  rescale = 1./255,\n",
        "                  rotation_range = 30,\n",
        "                  horizontal_flip = True,\n",
        "                  shear_range = 0.3,\n",
        "                  fill_mode = 'nearest',\n",
        "                  width_shift_range = 0.2,\n",
        "                  height_shift_range = 0.2,\n",
        "                  zoom_range = 0.1\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(\n",
        "                  rescale = 1./255,\n",
        "                  rotation_range = 30,\n",
        "                  horizontal_flip = True,\n",
        "                  shear_range = 0.3,\n",
        "                  fill_mode = 'nearest',\n",
        "                  width_shift_range = 0.2,\n",
        "                  height_shift_range = 0.2,\n",
        "                  zoom_range = 0.1\n",
        ")"
      ],
      "metadata": {
        "id": "m8Ksxrhepd2H"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Target"
      ],
      "metadata": {
        "id": "6iqeD7ZNrOh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size = (150, 150),\n",
        "    batch_size = 10,\n",
        "    class_mode = 'categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size = (150, 150),\n",
        "    batch_size = 10,\n",
        "    class_mode = 'categorical'\n",
        ")"
      ],
      "metadata": {
        "id": "a1qTv9g_rQf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs = {}):\n",
        "    if(logs.get('accuracy') > 0.99):\n",
        "      print('\\nAkurasi mencapai 99%')\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()"
      ],
      "metadata": {
        "id": "U1Id3lRxr_KI"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CNN**"
      ],
      "metadata": {
        "id": "I4yIgPd-tkTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "          tf.keras.layers.Conv2D(16, (3, 3), activation = 'relu', input_shape = (150,150, 3)),\n",
        "          tf.keras.layers.MaxPooling2D(2, 2),\n",
        "          tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu'),\n",
        "          tf.keras.layers.MaxPooling2D(2, 2),\n",
        "          tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu'),\n",
        "          tf.keras.layers.MaxPooling2D(2, 2),\n",
        "          tf.keras.layers.Flatten(),\n",
        "          tf.keras.layers.Dense(200, activation= 'relu'),\n",
        "          tf.keras.layers.Dropout(0.3, seed=122),\n",
        "          tf.keras.layers.Dense(500, activation= 'relu'),\n",
        "          tf.keras.layers.Dropout(0.5, seed=122),\n",
        "          tf.keras.layers.Dense(2, activation= 'sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "b63pO8j6tpHL"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "REI2ID6yvjgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = 'Adam',\n",
        "              metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "m3XfOzY_wNnn"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "            train_generator,\n",
        "            steps_per_epoch = 9,\n",
        "            epochs = 25,\n",
        "            validation_data = val_generator,\n",
        "            validation_steps = 1,\n",
        "            verbose = 1,\n",
        "            callbacks = [callbacks]\n",
        ")"
      ],
      "metadata": {
        "id": "moczH4VbwpQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label = 'Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label = 'Validation Accuracy')\n",
        "plt.title('Training and Validation accuracy')\n",
        "plt.legend(loc = 'best')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label = 'Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label = 'Validation Loss')\n",
        "plt.title('Training and Validation accuracy')\n",
        "plt.legend(loc = 'best')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "15jrzWrBy3qx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Klasifikasi"
      ],
      "metadata": {
        "id": "XQ3mZ1sP3lES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "\n",
        "  path = fn\n",
        "  img = image.load_img(path, target_size = (150, 150))\n",
        "  imgplot = plt.imshow(img)\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis = 0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size = 100)\n",
        "\n",
        "  print(fn)\n",
        "  \n",
        "  class_list = os.listdir(train_dir)\n",
        "\n",
        "  for j in range(42):\n",
        "    if classes[0][j] == 1. :\n",
        "      print('This image belongs to class', class_list[j-1])\n",
        "      break"
      ],
      "metadata": {
        "id": "WW_L0RkT3rdD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}